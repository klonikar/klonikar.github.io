<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="Content-Security-Policy" content="script-src 'self' 'unsafe-inline' 'unsafe-eval'; style-src 'self' 'unsafe-inline'; media-src *; img-src 'self' data: content:;">
  <meta name="format-detection" content="telephone=no">
  <meta name="msapplication-tap-highlight" content="no">
  <!--meta name="viewport" content="user-scalable=no, initial-scale=1, maximum-scale=1, minimum-scale=1, width=device-width, height=device-height" /-->
  <meta name="viewport" content="user-scalable=yes, width=device-width, height=device-height" />
  <title>AI Based Interrogation System</title>

  <link rel="stylesheet" type="text/css" href="css/app_styles.css" />
  <script src="js/face-api.js"></script>
  <script src="js/commons.js"></script>
  <script type="text/javascript" src="js/pouchdb.min.js"> </script>
  <!-- link rel="stylesheet" href="css/index.css" -->
  <!--link rel="stylesheet" href="css/styles.css"-->
  <link rel="stylesheet" href="css/materialize.css">
  <script type="text/javascript" src="js/jquery-2.1.1.min.js"></script>
  <script src="js/materialize.min.js"></script>
  <style type="text/css">
    #facesContainer {
      margin-top: 5px;
      min-height: 160px;
      max-height: 160px;
      overflow: auto;
      margin-bottom: 5px;
    }

    #facesContainer canvas {
      margin-top: 5px;
      margin-left: 10px;
      min-height: 100px;
      max-height: 100px;
    }

    #selectedFaces {
      margin-top: 5px;
      min-height: 250px;
      max-height: 250px;
      overflow: auto;
    }

    #selectedFaces canvas {
      margin-top: 5px;
      margin-left: 10px;
      min-height: 100px;
      max-height: 100px;
    }

    .recognized_image_container {
      max-width: 50%;
      display: inline-grid;
      min-height: 160px;
      max-height: 160px;
      overflow: auto;
    }

    .recognized_image {
      /*max-width: 55%;*/
      min-height: 150px;
      max-height: 150px;
    }

    .selected_recognized_image {
      max-width: 25%;
      min-height: 150px;
      max-height: 150px;
    }

    .confirmationButton {
      max-width: 75%;
      border-radius: 8px;
      border-color: #2ab7a9;
      margin-left: 10px;
    }
    .header {
    background-color: #c1a300;
    height: 70px; 
    display: flex;
    align-items: center; 
    justify-content: center; 
    padding: 0 10px; 
    text-align: center;
}

.header .logo-container {
    display: flex;
    justify-content: space-between;
    align-items: center;
    width: 100%;
    height: 100%;
  }

.header .logo {
    height: 80%; 
    width: auto; 
}

.header .title-container {
    text-align: center;
    flex: 1; 
    color: #1a237e; 
}
.header .title-container h1,
.header .title-container h4 {
    margin: 0;
}

.header .title-container h1 {
    font-size: 24px; 
}

.header .title-container h4 {
    font-size: 16px; 
  }
.header_welcome_text{
  color: #1a237e;
}

  </style>
</head>
<body>
  <div class="app">
    <header class="header">
      <div class="logo-container">
          <img src="./images/indian_navy1.png" alt="Logo 1" class="logo">
          <div class="title-container">
              <h1 class="header_welcome_text">SATYAPAN.AI</h1>
              <h4>AI Based Interrogation Systems</h4>
          </div>
          <img src="./images/logo-1.png" alt="Logo 2" class="logo">
      </div>
  </header>
  
  <div id="navbar"></div>
  <div class="center-content page-container">
    <fieldset class="fieldsetCustom">
      <legend>Start/Stop/Switch</legend>
      <button id="btnToggleCamera" class="smallMarginRight">Start Camera</button>
      <button id="btnSwitchCamera">Switch Camera</button>
    </fieldset>

    <fieldset class="fieldsetCustom">
      <legend>Status</legend>
      <label id="status"></label>
    </fieldset>
    <div class="progress" id="loader">
      <div class="indeterminate"></div>
    </div>
    <div>
        <image id="hiddenPreview" style="max-width: 100%;display: none;" >
    </div>
    <div style="position: relative" class="margin">
      <video onloadedmetadata="onPlay(this)" id="inputVideo" autoplay muted playsinline></video>
      <canvas id="overlay" />
    </div>
    <b>Detected Faces:</b>
    <div id="facesContainer" class="row side-by-side"></div>
    <!--
    <b>Original Faces:</b>
      <div id="originalFacesContainer" class="row side-by-side"></div>
    -->
    <div class="highlightedSection row side-by-side" id="registeredFaceImages" style="display: none;">
    </div>
    <b> Selected Faces: </b>
    <br/>
    <div class="row side-by-side" id="selectedFaces"> 
    </div>
    <div class="row side-by-side"> 
      <label for="selectedFacesName">Name:</label>
      <input type="text" id="selectedFacesName" class="bold" placeholder="Enter Person Name" />
      <button class="waves-effect waves-light btn" onclick="registerFaces();" >Register</button>
    </div>

  </div>
  </div>
  <!-- <footer class="footer">
    <button class="nav-button"><span class="material-icons">home</span></button>
    <button class="nav-button"><span class="material-icons">apps</span></button>
    <button class="nav-button"><span class="material-icons">settings</span></button>
    <button class="nav-button"><span class="material-icons">person</span></button>
</footer> -->
  <footer>
    <img src="images/logo_36x36.png" >
    <span class="footer_area">Powered By INICAI and PTPL </span>
  </footer>

  <script src="cordova.js"></script>

  <script>
    let forwardTimes = [];
    let isCameraOn = false;
    let use_cordova_plugin = window.cordova;
    let globalTimeout = use_cordova_plugin ? 200 : 500;
    let faceMatcher = null;
    let defaultCamera = 'back';
    let defaultZoomLevel = 10;
    let faces_db = null;
    let person_db = null;

    // Default settings. 
    const SSD_MOBILENETV1 = 'ssd_mobilenetv1'
    const TINY_FACE_DETECTOR = 'tiny_face_detector'

    let selectedFaceDetector = SSD_MOBILENETV1

    let maxFRThreshold = 0.55

    // ssd_mobilenetv1 options
    let minConfidence = 0.5

    // tiny_face_detector options
    let inputSize = 512
    let scoreThreshold = 0.5
    // end default settings

    function getCurrentFaceDetectionNet() {
      if (selectedFaceDetector === SSD_MOBILENETV1) {
        return faceapi.nets.ssdMobilenetv1
      }
      if (selectedFaceDetector === TINY_FACE_DETECTOR) {
        return faceapi.nets.tinyFaceDetector
      }
    }

    function isFaceDetectionModelLoaded() {
      return !!getCurrentFaceDetectionNet().params
    }

    function getFaceDetectorOptions() {
      return selectedFaceDetector === SSD_MOBILENETV1
        ? new faceapi.SsdMobilenetv1Options({ minConfidence })
        : new faceapi.TinyFaceDetectorOptions({ inputSize, scoreThreshold })
    }

    async function docExists(db, docId, options={}) {
      let ret = await db.get(docId, options).then((doc) => doc).catch(() => false)
      return ret
    }

    async function attachmentExists(db, docId, attachmentId) {
      let ret = await db.getAttachment(docId, attachmentId).then((doc) => doc).catch(() => false)
      return ret
    }

    // doc returned by allDocs when include_docs and attachments is not specified
    async function removeFromDb(db, doc) { await db.remove(doc.id, doc.value.rev) }

    async function clearFacesDB(db) {
        let alldocs = await db.allDocs()
        await Promise.all(alldocs.rows.map(
          async doc => {
            removeFromDb(db, doc)
          }))
    }

    async function saveFaceToDB(className, selectedFacesData, clearDb = false) {
      const maxAvailableImagesPerClass = 5
      const numImagesForTraining = Math.min(selectedFacesData.length, maxAvailableImagesPerClass)

      let db = faces_db;

      if(clearDb) {
        console.log('Clearing existing face embedding DB...')
        await clearFacesDB(db)
      }

      let doc = {
        '_id': className,
        'name': className
      }
      let existingDoc = await docExists(db, className)
      if(existingDoc) {
        console.log('doc for ' + className + ' exists.', existingDoc)
        doc = existingDoc
      }
      else {
        doc._attachments = {}
      }
      for (let i = 0;i < numImagesForTraining; i++) {
        const imageUri = selectedFacesData.get(i)
        let attachmentId = `${className}${i}.png`
        let embeddingAttachmentId = `${attachmentId.split(".")[0]}.bin`
        let exists = await attachmentExists(db, className, attachmentId)
        if(exists) {
          console.log('Embedding exists for ' + className + ' and ' + attachmentId)
          //continue
        }
        console.log('Embedding will be created for ' + className + ' and ' + attachmentId)
        const img = await faceapi.fetchImage(imageUri)
        let embedding = await faceapi.computeFaceDescriptor(img)
        let embeddingType = 'application/octet-stream'
        // Strip off "data:image/png;base64," from data url
        doc._attachments[attachmentId] = {
          'content_type': 'text/png',
          'data': img.src.split('base64,')[1]
        }
        doc._attachments[embeddingAttachmentId] = {
          'content_type': embeddingType,
          'data': new Blob([embedding], {'type': embeddingType})
        }
        // Add embedding to faceMatcher
        if(faceMatcher) {
          let existingDescriptor = faceMatcher.labeledDescriptors.filter(d => d._label == className)
          if(existingDescriptor && existingDescriptor.length) {
            existingDescriptor[0]._descriptors.push(embedding)
          }
          else {
            let desc = new faceapi.LabeledFaceDescriptors(className, [embedding])
            faceMatcher.labeledDescriptors.push(desc)
          }
        }
      }
      let savedDoc = await db.put(doc)
      console.log('Saved embedding and image: ', savedDoc)
    }

    // From https://gist.github.com/sketchpunk/f5fa58a56dcfe6168a9328e7c32a4fd4
    function base64_to_float32Array(attachment) {
      let blob  = window.atob(attachment),
          fLen  = blob.length / Float32Array.BYTES_PER_ELEMENT,           // How many floats can be made, but be even
          dView = new DataView(new ArrayBuffer(Float32Array.BYTES_PER_ELEMENT)),  // ArrayBuffer/DataView to convert 4 bytes into 1 float.
          fAry  = new Float32Array(fLen),                     // Final Output at the correct size
          p     = 0;                                // Position

      for(let j=0; j < fLen; j++){
        p = j * 4;
        dView.setUint8(0,blob.charCodeAt(p));
        dView.setUint8(1,blob.charCodeAt(p+1));
        dView.setUint8(2,blob.charCodeAt(p+2));
        dView.setUint8(3,blob.charCodeAt(p+3));
        fAry[j] = dView.getFloat32(0,true);
      }
      return fAry;
    }

    // fetch first image of each class and compute their descriptors
    async function createFaceMatcher() {
      let db = faces_db;

      let alldocs = await db.allDocs({include_docs: true, attachments: true})
      let labeledFaceDescriptors = alldocs.rows.map(row => {
        let descriptors = Object.keys(row.doc._attachments).filter(k => k.endsWith('.bin')).map(k => {
          let attachment = row.doc._attachments[k]
          return base64_to_float32Array(attachment.data)
        })
        return new faceapi.LabeledFaceDescriptors(
            row.doc.name,
            descriptors
          )
      })
      if(labeledFaceDescriptors.length == 0) {
        labeledFaceDescriptors = new faceapi.LabeledFaceDescriptors('unknown', [new Float32Array(128)])
      }
      return new faceapi.FaceMatcher(labeledFaceDescriptors, maxFRThreshold)
    }

    function updateTimeStats(timeInMs) {
      forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
      const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
      let timeStats = `Time/Frame ${Math.round(avgTimeInMs)} ms, FPS ${faceapi.utils.round(1000 / avgTimeInMs)}`
      $('#status').html('<span class="success">' + timeStats + '</span>');
    }

    async function registerFaces() {
      let name = document.getElementById("selectedFacesName").value;
      let db = faces_db;
      let faceRec = await docExists(db, name);
      if(faceRec) {
        let ret = confirm(`${name} is already registered. Do you want to continue?`);
        if(!ret) {
          return;
        }
      }
      console.log("Registering selected faces as: " + name);
      var faces = $("#selectedFaces canvas");
      var selectedFaces = faces.filter(f => { return faces[f].style.opacity && faces[f].style.opacity == 0.5; });
      var selectedFacesData = selectedFaces.map(f => { return selectedFaces[f].toDataURL(); });
      console.log(selectedFacesData);
      await saveFaceToDB(name, selectedFacesData);
      selectedFaces.map(f => { selectedFaces[f].parentNode.remove(); });
    }

    function selectedFaceImageClickHandler(elem) {
      elem.style.opacity = elem.style.opacity && elem.style.opacity != 1 ? 1 : 0.5;
    }

    function faceImageClickHandler(elem, containerElem) {
      elem.className = 'selected_recognized_image'
      let span = document.createElement("span");
      span.appendChild(elem);
      //span.appendChild(document.createElement('br'));
      elem.onclick = function() {
        return selectedFaceImageClickHandler(elem)
      }
      $('#selectedFaces').append(span);
      containerElem.remove()
    };

    function addCellToRow(cellData, row) {
      let cell = document.createElement('td')
      cell.innerHTML = cellData
      row.appendChild(cell)
    }

    function showInterrogationHistory(interrogationHistory, personName, parentDivName) {
      if(!interrogationHistory) {
        console.log("No interrogation history found for ", personName)
        $('#' + parentDivName).empty()
        return
      }
      let table = document.createElement('table')
      let thead = document.createElement('thead')
      let headrow = document.createElement('tr')
      let columnHeaders = ['Date', 'Time', 'Lat', 'Long', 'Vessel', 'Interrogator', 'Docs', 'Remarks']
      columnHeaders.forEach(c => {
        let cell = document.createElement('td')
        cell.innerHTML = `<b>${c}</b>`
        headrow.appendChild(cell)
      })
      thead.appendChild(headrow)
      table.appendChild(thead)
      let tbody = document.createElement('tbody')
      interrogationHistory.forEach(h => {
        let row = document.createElement('tr')
        addCellToRow(h['date'], row)
        addCellToRow(h['time'], row)
        addCellToRow(h['latitude'], row)
        addCellToRow(h['longitude'], row)
        addCellToRow(h['locationName'], row)
        addCellToRow(h['interrogator'], row)
        addCellToRow(h['documents'], row)
        addCellToRow(h['remarks'], row)
        tbody.appendChild(row)
      })
      table.appendChild(tbody)
      $('#' + parentDivName).empty()
      $('#' + parentDivName).append(table)
    }

    async function showRegisteredImages(label) {
      let name = label.split('(')[0].trim()
      $('#registeredFaceImages').get(0).style.display = 'block'
      $('#registeredFaceImages').empty()
      let db = faces_db;
      let selectedPersonFaceDoc = await docExists(db, name, {attachments: true})
      if(!selectedPersonFaceDoc) {
        console.log(`No face registered by ${name}`)
        $('#registeredFaceImages').html(`No face registered by ${name}`)
        return
      }
      let personRec = await docExists(person_db, name)
      if(personRec) {
        let identificationMarks = personRec.identificationMarks ? personRec.identificationMarks : 'None'
        let personDetails = '<table><thead><tr><td><b>Name</b></td><td><b>Country</b></td><td><b>Age</b></td><td><b>Gender</b></td><td><b>Category</b></td></tr></thead>'
        personDetails += `<tbody><tr><td>${personRec.name}</td><td>${personRec.country}</td><td>${personRec.age}</td><td>${personRec.gender}</td><td>${personRec.category}</td></tr>`
        personDetails += `<tr><td><b>Identification Marks:</b></td><td>${identificationMarks}</td></tbody></table>`
        $('#registeredFaceImages').append(personDetails)
      }
      else {
        $('#registeredFaceImages').append(`<b>Registered Images of ${name}</b><br/>`)
      }

      let imageAttachments = Object.keys(selectedPersonFaceDoc._attachments).filter(k => k.split('.')[1] == 'png')
      imageAttachments.forEach((a, i) => {
          let img = new Image()
          img.src = "data:image/png;base64," + selectedPersonFaceDoc._attachments[a].data
          img.className = 'selected_recognized_image'
          $('#registeredFaceImages').append(img)
      })
      let span = document.createElement('span')
      span.classList.add('row', 'side-by-side')
      let editButton = document.createElement('button')
      editButton.className = 'confirmationButton'
      editButton.innerHTML = 'Edit ' + name
      editButton.onclick = function() {
        return confirmRecognizedFace(label)
      }
      let hideButton = document.createElement('button')
      hideButton.className = 'confirmationButton'
      hideButton.innerHTML = 'Hide Details'
      hideButton.onclick = function() {
        return $('#registeredFaceImages').hide()
      }
      span.append(editButton)
      span.append(hideButton)
      $('#registeredFaceImages').append('<br/>')
      $('#registeredFaceImages').append(span)
      let historyDiv = document.createElement('div')
      historyDiv.id = 'historyDiv'
      $('#registeredFaceImages').append(historyDiv)
      showInterrogationHistory(personRec.interrogationHistory, personRec.name, 'historyDiv')
    }

    function confirmRecognizedFace(recognizedFaceLabel) {
      ret = confirm("Edit " + recognizedFaceLabel + '?')
      if(ret) {
        window.location.href = 'editDetails.html?id=' + recognizedFaceLabel.split('(')[0].trim();
      }
    }

    async function getBoxColor(label) {
      let faceName = label.split('(')[0].trim()
      if(faceName == 'unknown') {
        return 'red';
      }
      else {
        let faceExists = await docExists(person_db, faceName);
        if(faceExists)
          return 'green';
        else
          return '#ebab34';
      }
    }

    async function performDetection(videoEl) {
      const ts = Date.now()
      const options = getFaceDetectorOptions();
      const detections = await faceapi.detectAllFaces(videoEl, options).withFaceLandmarks().withFaceDescriptors();

      updateTimeStats(Date.now() - ts)

      if (detections) {
        const alignedDetections = detections.map((det) => det.alignedRect )
        const originalDetections = detections.map((det) => det.detection )
        const faceImages = await faceapi.extractFaces(videoEl, originalDetections)
        const alignedFaceImages = await faceapi.extractFaces(videoEl, alignedDetections)

        const canvas = $('#overlay').get(0)
        let displayedImage = videoEl.tagName.toLocaleLowerCase() == 'video' ? videoEl : $('#inputVideo').get(0)
        const dims = faceapi.matchDimensions(canvas, displayedImage, videoEl.tagName.toLocaleLowerCase() == 'video')
        // resize detection and landmarks in case displayed image is smaller than
        // original size
        const resizedResults = faceapi.resizeResults(detections, dims)
        const results_images = zip2(resizedResults, alignedFaceImages)

        $('#facesContainer').empty()
        results_images.forEach(async (result_and_image) => {
          let [result, croppedCanvas] = result_and_image
          let descriptor = result.descriptor
          let detection = result.detection
          const label = faceMatcher.findBestMatch(descriptor).toString()
          const boxColor = await getBoxColor(label);
          const options = { label, boxColor }
          const drawBox = new faceapi.draw.DrawBox(detection.box, options)
          drawBox.draw(canvas)

          croppedCanvas.className = 'recognized_image'
          croppedCanvas.title = label
          croppedCanvas.onclick = function() {
            return faceImageClickHandler(croppedCanvas, containerElem);
          };

          let containerElem = document.createElement('span')
          containerElem.className = 'recognized_image_container'
          containerElem.appendChild(croppedCanvas)
          let faceName = label.split('(')[0].trim()
          if(faceName != 'unknown') {
            let button = document.createElement('button')
            button.className = 'confirmationButton'
            button.innerHTML = 'View ' + faceName
            button.onclick = function() {
              return showRegisteredImages(label)
            }
            containerElem.appendChild(button)
          }
          $('#facesContainer').append(containerElem)
        })
        //faceapi.draw.drawDetections(canvas, faceapi.resizeResults(detections, dims))
        //$('#originalFacesContainer').empty()
        //faceImages.forEach(canvas => $('#originalFacesContainer').append(canvas))

      }
      setTimeout(() => onPlay(), globalTimeout);
    }

    async function onPlay() {
      const videoEl = $('#inputVideo').get(0);

      if(use_cordova_plugin) {
        if(!isCameraOn || !isFaceDetectionModelLoaded())
          return setTimeout(() => onPlay(), globalTimeout);

        let cameraOptions = {
          quality: 85
        };
        let successCallback = function (imgData) {
          $('#status').html('Ok');
          let hiddenPreview = $('#hiddenPreview').get(0);
          let base64Image = 'data:image/jpeg;base64,' + imgData;
          hiddenPreview.onload = function() {
            performDetection(hiddenPreview);
          };
          $('#inputVideo').attr('src', base64Image);
          $('#hiddenPreview').attr('src', base64Image);
          //CameraPreview.hide();
        };
        let errorCallback = function (pluginResult) {
          //$('#status').html('<span class="error">' + pluginResult + '</span>');
          $('#status').html('<span class="error">' + 'Camera is getting ready... Please wait.' + '</span>');
          setTimeout(() => onPlay(), globalTimeout)
        };
        CameraPreview.takeSnapshot(cameraOptions, successCallback, errorCallback);
      }
      else {
        if(videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
          return setTimeout(() => onPlay(), globalTimeout);
        performDetection(videoEl);
      }
    }

    function startCamera() {
        // Initialize the CameraPreview
        let cwidth = String(window.screen.width - 40);
        let cheight = String(window.screen.width - 40); // same as width
        let optCameraDirection = defaultCamera;
        CameraPreview.startCamera({x: '0', y: '0', width: cwidth, height: cheight, camera: optCameraDirection, tapPhoto: false, toBack: true, previewDrag: true});
        document.addEventListener("backbutton", stopCamera, false);
        isCameraOn = true;
        $('#btnToggleCamera').html('Stop Camera');
        $('#btnToggleCamera').on('click', stopCamera);
        let successCallback = function (pluginResult) {
          $('#status').html('<span class="success">Zoom: ' + pluginResult + '</span>');
        };
        let errorCallback = function (pluginResult) {
          $('#status').html('<span class="error">' + pluginResult + '</span>');
        };
        CameraPreview.setZoom(defaultZoomLevel, successCallback, errorCallback);

        onPlay();
    }

    function stopCamera() {
      CameraPreview.stopCamera();
      document.removeEventListener("backbutton", stopCamera, false);
      isCameraOn = false;
      $('#btnToggleCamera').html('Start Camera');
      $('#btnToggleCamera').on('click', startCamera);
    }

    function switchCamera() {
      let successCallback = function (pluginResult) {
        $('#status').html('<span class="success">' + pluginResult + '</span>');
      };
      let errorCallback = function (pluginResult) {
        $('#status').html('<span class="error">' + pluginResult + '</span>');
      };
      //CameraPreview.switchCamera(successCallback, errorCallback);
      stopCamera();
      defaultCamera = defaultCamera == 'back' ? 'front' : 'back'
      startCamera()
    }

    async function run() {
      document.body.style.minHeight = `${window.screen.height}px`;
      // load face detection model
      let faces_settings_db = new PouchDB('faces_settings_db')
      faces_db = new PouchDB('faces_db')
      person_db = new PouchDB('person_db')
      let settings = await docExists(faces_settings_db, 'settings')
      if(settings) { // Get from settings
        selectedFaceDetector = settings.faceDetector
        maxFRThreshold = settings.maxFRThreshold
        // ssd_mobilenetv1 options
        minConfidence = settings.minConfidence
        // tiny_face_detector options
        inputSize = settings.inputSize
        scoreThreshold = settings.scoreThreshold
        defaultCamera = 'camera' in settings ? settings.camera : defaultCamera
        defaultZoomLevel = 'zoom' in settings ? settings.zoom : defaultZoomLevel
      }
      else { // Save initial settings to db
        settings = {
          '_id': 'settings',
          'faceDetector': selectedFaceDetector,
          'maxFRThreshold': maxFRThreshold,
          'minConfidence': minConfidence,
          'inputSize': inputSize,
          'scoreThreshold': scoreThreshold,
          'camera': defaultCamera,
          'zoom': defaultZoomLevel
        }
        await faces_settings_db.put(settings)
      }

      $('#loader').show()
      await getCurrentFaceDetectionNet().load("weights/")
      await faceapi.loadFaceLandmarkModel('weights/')
      await faceapi.loadFaceRecognitionModel('weights/')
      $('#loader').hide()
      //$('#btnSwitchCamera').hide() // Hiding this as it does not work consistently

      faceMatcher = await createFaceMatcher();

      // try to access users webcam and stream the images
      // to the video element
      if(use_cordova_plugin) {
        $('#inputVideo').remove();
        let overlayParent = $('#overlay').get(0).parentNode;
        let imgOverlay = new Image();
        imgOverlay.id = 'inputVideo';
        //imgOverlay.style = "max-width: 50%";
        overlayParent.insertBefore(imgOverlay, overlayParent.children[0]);
        $('#btnSwitchCamera').on('click', switchCamera);
        startCamera();
      }
      else {
        // The following does not work for back cameras in android while using cordova.
        // cordova-camera-preview plugin needs to be used.
        /*
        let devices = await navigator.mediaDevices.enumerateDevices();
        let backCameras = devices.filter(d => d.kind.indexOf('back') >= 0);
        let frontCameras = devices.filter(d => d.label.indexOf('front') >= 0);
        let constraints = {
          audio: false,
          video: {
            //optional: [{sourceId: videoSource}]
            deviceId: {exact: backCameras[0].deviceId} // frontCameras[0].deviceId works
          }
        };
        const backCameraStream = await navigator.mediaDevices.getUserMedia(constraints);
        */
        const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
        const videoEl = $('#inputVideo').get(0)
        videoEl.srcObject = stream;
        onPlay();
      }
    }

    function updateResults() {
    }

    async function pageOnDeviceReady() {
      renderNavBar('#navbar', 'index.html')
      run()
    }

    if(use_cordova_plugin)
      document.addEventListener('deviceready', pageOnDeviceReady, false);
    else
      $(document).ready(function() {
      renderNavBar('#navbar', 'index.html')
      run()
    })

    window.onbeforeunload =  function(){
      console.log('before unload... stopping camera.')
      if(use_cordova_plugin)
        stopCamera();
    };

    /*
    window.onunload = function(){
      console.log('unload... stopping camera.')
      stopCamera();
    };
	*/

  </script>
</body>
</html>